{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "from sklearn import metrics as skmetrics\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# Imports from this project\n",
    "sys.path.insert(0, \"..\")\n",
    "from utils import paths\n",
    "from utils.input_output import load_feature_keys, load_feature_properties, load_preprocessed_data\n",
    "from utils.histograms import find_good_binning, get_hist, calc_pull\n",
    "from utils.merge_pdfs import merge_pdfs\n",
    "from model_B_classifier import DeepSetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Results from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features_B_classifier.json\", \"r\") as file:\n",
    "    feature_lists = json.load(file)\n",
    "    \n",
    "trained_model_names = [n.replace(\"features_\",\"\") for n in feature_lists.keys() if (paths.models_dir/n.replace(\"features_\",\"\")/paths.B_classifier_eval_file.name).is_file()]\n",
    "trained_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "\n",
    "for model_name in trained_model_names:\n",
    "    paths.update_B_classifier_name(model_name)\n",
    "    with open(paths.B_classifier_dir/\"eval_results.json\", \"r\") as file:\n",
    "        eval_results = json.load(file)\n",
    "        \n",
    "    for metric in eval_results.keys():\n",
    "        if metric != \"confusion_matrix_test\":\n",
    "            df_results.loc[model_name,metric] = eval_results[metric]\n",
    "            \n",
    "    if \"confusion_matrix_test\" in eval_results.keys():\n",
    "        df_results.loc[model_name,\"efficiency_Bd_test\"] = eval_results[\"confusion_matrix_test\"][0][0]\n",
    "        df_results.loc[model_name,\"efficiency_Bs_test\"] = eval_results[\"confusion_matrix_test\"][1][1]\n",
    "        \n",
    "with pd.option_context(\"display.float_format\", '${:,.3f}'.format):\n",
    "    print(df_results.sort_values(by=\"accuracy_test\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generare Feature Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features_B_classifier.json\", \"r\") as file:\n",
    "    feature_lists = json.load(file)\n",
    "    \n",
    "assert \"features_B_classifier_baseline\" in feature_lists.keys()\n",
    "assert \"features_B_classifier_all\" in feature_lists.keys()\n",
    "\n",
    "baseline_features = feature_lists[\"features_B_classifier_baseline\"]\n",
    "all_features = feature_lists[\"features_B_classifier_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lists with one feature added, each\n",
    "for feature in set(all_features) - set(baseline_features):\n",
    "    feature_lists[f\"features_B_classifier_baseline_with_{feature}\"] = baseline_features + [feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features_B_classifier.json\", \"w\") as file:\n",
    "    json.dump(feature_lists, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lists.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20b05ee88e26e7f23d90b869a85a4fb598ebc8861a40413c4d0961bc2f50b067"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('root_forge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
